{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8KQYvGDO7cg"
   },
   "outputs": [],
   "source": [
    "def dic2arg(config:dict):\n",
    "  arg = ''\n",
    "  for value in config:\n",
    "    arg += f'{value if str(config[value]) != \"False\" else \"\"} {\"\" if type(config[value]) == bool else config[value]} '\n",
    "  return arg\n",
    "\n",
    "def data_config(flip, color_aug, shuffle_caption):\n",
    "  return {\n",
    "    \"general\": {\n",
    "        \"flip_aug\": flip,\n",
    "        \"color_aug\": color_aug,\n",
    "        \"keep_tokens_separator\": \"|||\",\n",
    "        \"shuffle_caption\": shuffle_caption,\n",
    "        \"caption_tag_dropout_rate\": 0,\n",
    "        \"caption_extension\": \".txt\"\n",
    "    },\n",
    "    \"datasets\": []\n",
    "  }\n",
    "\n",
    "op = {\n",
    "    '--mixed_precision': 'bf16',\n",
    "    '--num_cpu_threads_per_process': 1,\n",
    "}\n",
    "\n",
    "def config(TrainType, model_train, flux_path, clip_l_path, t5xxl_fp16_path, vae_path, dim, alpha, train_textencode, optimizer_type, lr, lr_scheduler, epochs, save_every_n_epochs, save_every_n_steps, dataset, output_dir, output_name):\n",
    "  return {\n",
    "    '--pretrained_model_name_or_path': flux_path if TrainType == 'Flux' else model_train,\n",
    "    '--clip_l': clip_l_path if TrainType == 'Flux' else False,\n",
    "    '--t5xxl': t5xxl_fp16_path if TrainType == 'Flux' else False,\n",
    "    '--ae': vae_path if TrainType == 'Flux' else False,\n",
    "    '--cache_latents_to_disk': True,\n",
    "    '--save_model_as': 'safetensors',\n",
    "    '--sdpa': True,\n",
    "    '--persistent_data_loader_workers': True,\n",
    "    '--max_data_loader_n_workers': 2,\n",
    "    '--seed': 42,\n",
    "    '--gradient_checkpointing': True,\n",
    "    '--mixed_precision': 'bf16',\n",
    "    '--save_precision': 'bf16',\n",
    "    '--network_module': '\"networks.lora_flux\"' if TrainType == 'Flux' else '\"networks.lora\"',\n",
    "    '--network_dim': dim,\n",
    "    '--network_alpha': alpha,\n",
    "    '--network_train_unet_only': False if train_textencode else True,\n",
    "    '--network_args': \"train_t5xxl=True\" if train_textencode and TrainType == 'Flux' else False,\n",
    "    '--optimizer_type': optimizer_type,\n",
    "    '--optimizer_args': '\"relative_step=False\" \"scale_parameter=False\" \"warmup_init=False\"' if optimizer_type == 'adafactor' else False,\n",
    "    '--learning_rate': lr,\n",
    "    '--lr_scheduler': 'constant_with_warmup' if optimizer_type == 'adafactor' else lr_scheduler,\n",
    "    '--unet_lr': False, \n",
    "    '--text_encoder_lr': False, \n",
    "    '--cache_text_encoder_outputs': False,\n",
    "    '--cache_text_encoder_outputs_to_disk': False,\n",
    "    '--fp8_base': True if TrainType == 'Flux' else False,\n",
    "    '--highvram': True,\n",
    "    '--max_train_epochs': epochs,\n",
    "    '--save_every_n_epochs': False if save_every_n_epochs <= 0 else save_every_n_epochs,\n",
    "    '--save_every_n_steps': False if save_every_n_steps <= 0 else save_every_n_steps,\n",
    "    '--dataset_config': f'\"{dataset}\"',\n",
    "    '--output_dir': f'\"{output_dir}\"',\n",
    "    '--output_name': f'\"{output_name}\"',\n",
    "    '--timestep_sampling': 'shift' if TrainType == 'Flux' else False,\n",
    "    '--discrete_flow_shift': 3.1582 if TrainType == 'Flux' else False,\n",
    "    '--model_prediction_type': 'raw' if TrainType == 'Flux' else False,\n",
    "    '--guidance_scale': 1.0 if TrainType == 'Flux' else False,\n",
    "    '--max_bucket_reso': 2048,\n",
    "    '--min_bucket_reso': 256 if TrainType == 'SD15' else 512,\n",
    "  }\n",
    "\n",
    "def config_cp(TrainType, model_train, flux_path, clip_l_path, t5xxl_fp16_path, vae_path, optimizer_type, lr, lr_scheduler, epochs, save_every_n_epochs, save_every_n_steps, dataset, output_dir, output_name):\n",
    "  return {\n",
    "    '--pretrained_model_name_or_path': flux_path if TrainType == 'Flux' else f'\"{model_train}\"',\n",
    "    '--clip_l': clip_l_path if TrainType == 'Flux' else False,\n",
    "    '--t5xxl': t5xxl_fp16_path if TrainType == 'Flux' else False,\n",
    "    '--ae': vae_path if TrainType == 'Flux' else False,\n",
    "    '--cache_latents_to_disk': True,\n",
    "    '--save_model_as': 'safetensors',\n",
    "    '--sdpa': True,\n",
    "    '--persistent_data_loader_workers': True,\n",
    "    '--max_data_loader_n_workers': 2,\n",
    "    '--seed': 42,\n",
    "    '--gradient_checkpointing': True,\n",
    "    '--mixed_precision': 'bf16',\n",
    "    '--save_precision': 'fp16',\n",
    "    '--optimizer_type': optimizer_type,\n",
    "    '--optimizer_args': '\"relative_step=False\" \"scale_parameter=False\" \"warmup_init=False\"' if optimizer_type == 'adafactor' else False,\n",
    "    '--learning_rate': lr,\n",
    "    '--lr_scheduler': 'constant_with_warmup' if optimizer_type == 'adafactor' else lr_scheduler,\n",
    "    '--unet_lr': False, \n",
    "    '--text_encoder_lr': False, \n",
    "    '--cache_text_encoder_outputs': True if TrainType == 'Flux' else False,\n",
    "    '--cache_text_encoder_outputs_to_disk': True if TrainType == 'Flux' else False,\n",
    "    '--fp8_base': True if TrainType == 'Flux' else False,\n",
    "    '--highvram': True,\n",
    "    '--max_train_epochs': epochs,\n",
    "    '--save_every_n_epochs': False if save_every_n_epochs <= 0 else save_every_n_epochs,\n",
    "    '--save_every_n_steps': False if save_every_n_steps <= 0 else save_every_n_steps,\n",
    "    '--dataset_config': f'\"{dataset}\"',\n",
    "    '--output_dir': f'\"{output_dir}\"',\n",
    "    '--output_name': f'\"{output_name}\"',\n",
    "    '--timestep_sampling': 'shift' if TrainType == 'Flux' else False,\n",
    "    '--discrete_flow_shift': 3.1582 if TrainType == 'Flux' else False,\n",
    "    '--model_prediction_type': 'raw' if TrainType == 'Flux' else False,\n",
    "    '--guidance_scale': 1.0 if TrainType == 'Flux' else False,\n",
    "    '--max_bucket_reso': 2048,\n",
    "    '--min_bucket_reso': 256 if TrainType == 'SD15' else 512,\n",
    "  }\n",
    "\n",
    "def extra(TrainType, output_name, author,save_state, resume, wandbapi, sample_steps, runcode):\n",
    "  if runcode:\n",
    "    wandbapi = ''\n",
    "  return {\n",
    "      '--metadata_title': f'\"{output_name}\"',\n",
    "      '--metadata_author': f'\"{author}\"',\n",
    "      '--metadata_description': '\"training by trainlora.vn\"',\n",
    "      '--metadata_license': False, # \"MIT\"\n",
    "      '--metadata_tags': False, # \"sdvn.me\"\n",
    "      '--no_metadata': False,\n",
    "      '--training_comment': f'\"training by trainlora.vn\"',\n",
    "      '--save_n_epoch_ratio': False,\n",
    "      '--save_last_n_epochs': False,\n",
    "      '--save_last_n_epochs_state': False,\n",
    "      '--save_last_n_steps': False,\n",
    "      '--save_last_n_steps_state': False,\n",
    "      '--save_state': save_state,\n",
    "      '--save_state_on_train_end': True,\n",
    "      '--resume': f'\"{resume}\"' if resume != '' else False, #Path\n",
    "      '--log_with': 'wandb' if wandbapi!='' else False, # tensorboard,wandb,all\n",
    "      '--wandb_run_name': f'\"{TrainType}lora_{output_name}\"' if wandbapi!='' else False,\n",
    "      '--wandb_api_key': wandbapi if wandbapi!='' else False,\n",
    "      '--sample_every_n_steps': False if sample_steps <= 0 else sample_steps,\n",
    "      '--sample_at_first': False if sample_steps <= 0 else True,\n",
    "      '--sample_every_n_epochs': False,\n",
    "      '--sample_prompts': '/content/prompt.txt',\n",
    "      '--sample_sampler': 'euler',\n",
    "  }\n",
    "\n",
    "def extra_cp(TrainType, output_name, author,save_state, resume, wandbapi, sample_steps, runcode):\n",
    "  if runcode:\n",
    "    wandbapi = ''\n",
    "  return {\n",
    "      '--metadata_title': f'\"{output_name}\"',\n",
    "      '--metadata_author': f'\"{author}\"',\n",
    "      '--metadata_description': '\"training by trainlora.vn\"',\n",
    "      '--metadata_license': False, # \"MIT\"\n",
    "      '--metadata_tags': False, # \"sdvn.me\"\n",
    "      '--no_metadata': False,\n",
    "      '--save_n_epoch_ratio': False,\n",
    "      '--save_last_n_epochs': False,\n",
    "      '--save_last_n_epochs_state': False,\n",
    "      '--save_last_n_steps': False,\n",
    "      '--save_last_n_steps_state': False,\n",
    "      '--save_state': save_state,\n",
    "      '--save_state_on_train_end': True,\n",
    "      '--resume': f'\"{resume}\"' if resume != '' else False, #Path\n",
    "      '--log_with': 'wandb' if wandbapi!='' else False, # tensorboard,wandb,all\n",
    "      '--wandb_run_name': f'\"{TrainType}lora_{output_name}\"' if wandbapi!='' else False,\n",
    "      '--wandb_api_key': wandbapi if wandbapi!='' else False,\n",
    "      '--sample_every_n_steps': False if sample_steps <= 0 else sample_steps,\n",
    "      '--sample_at_first': False if sample_steps <= 0 else True,\n",
    "      '--sample_every_n_epochs': False,\n",
    "      '--sample_prompts': '/content/prompt.txt',\n",
    "      '--sample_sampler': 'euler',\n",
    "  }\n",
    "\n",
    "def prompt(sample_prompt, sample_size, TrainFolder):\n",
    "  prompt = f\"\"\"#prompt 1\n",
    "{sample_prompt if sample_prompt != \"\" else random_sample(TrainFolder)} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}\n",
    "#prompt 2\n",
    "{random_sample(TrainFolder)} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}\n",
    "#prompt 3\n",
    "{random_sample(TrainFolder)} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}\"\"\"\n",
    "  write_file('/content/prompt.txt',prompt)\n",
    "\n",
    "def dataset_file(resolution, batch_size, image_dir, num_repeats, data_config, dataset):\n",
    "  resolutions = resolution.split(',')\n",
    "  index = 0\n",
    "  for resolution in resolutions:\n",
    "    if '-' in resolution:\n",
    "      b = int(resolution.split('-')[1])\n",
    "      r = int(resolution.split('-')[0])\n",
    "    else:\n",
    "      b = batch_size\n",
    "      r = int(resolution)\n",
    "    data_config[\"datasets\"].append({\n",
    "              \"batch_size\": b,\n",
    "              \"enable_bucket\": True,\n",
    "              \"resolution\": [r, r],\n",
    "              \"subsets\": []\n",
    "              })\n",
    "    for dir in check_sub_dir(image_dir):\n",
    "      data_config[\"datasets\"][index][\"subsets\"] += [{\n",
    "          \"image_dir\": dir,\n",
    "          \"num_repeats\": repeat_dir(dir,num_repeats)\n",
    "      }]\n",
    "    index += 1\n",
    "\n",
    "  with open(dataset, \"w\") as file:\n",
    "      toml.dump(data_config, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
