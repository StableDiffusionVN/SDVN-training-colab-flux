---
job: "extension"
config:
  name: "my_first_lora_v1"
  process:
    - type: 'sd_trainer' #'sd_trainer' 'ui_trainer'
      training_folder: "/content/Lora"
      device: cuda:0
      trigger_word: null
      # performance_log_every: 10
      network:
        type: "lora"
        linear: 32
        linear_alpha: 32
        # conv: 16
        # conv_alpha: 16
        # lokr_full_rank: true
        # lokr_factor: -1
        # network_kwargs:
        #   ignore_if_contains: []
      save:
        dtype: float16
        save_every: 250
        max_step_saves_to_keep: 100
        # save_format: "diffusers"
        push_to_hub: false
      datasets:
        - folder_path: "/content/"
          control_path: null
          mask_path: null
          mask_min_value: 0.1
          # default_caption: ""
          caption_ext: "txt"
          caption_dropout_rate: 0.05
          cache_latents_to_disk: true
          # is_reg: false
          # network_weight: 1
          resolution: [1024]
          # controls: []
          # shrink_video_to_frames: true
          # num_frames: 1
          # do_i2v: true
      train:
        batch_size: 1
        # bypass_guidance_embedding: false
        steps: 3000
        gradient_accumulation: 1
        train_unet: true
        train_text_encoder: false
        gradient_checkpointing: true
        noise_scheduler: "flowmatch"
        optimizer: "adamw8bit"
        # timestep_type: "sigmoid"
        # content_or_style: "balanced"
        # optimizer_params:
        #   weight_decay: 0.0001
        # unload_text_encoder: false
        # cache_text_embeddings: false
        lr: 0.0001
        ema_config:
          use_ema: false
          ema_decay: 0.99
        skip_first_sample: false
        disable_sampling: false
        dtype: "bf16"
        # diff_output_preservation: false
        # diff_output_preservation_multiplier: 1
        # diff_output_preservation_class: "person"
      model:
        name_or_path: "black-forest-labs/FLUX.1-dev"
        low_vram: false
        arch: "flux"
        quantize: true
        # qtype: "qfloat8"
        # quantize_te: true
        # qtype_te: "qfloat8"
        # model_kwargs: {}
      sample:
        sampler: "flowmatch"
        sample_every: 250
        width: 1024
        height: 1024
        samples:
          - prompt: "woman with red hair, playing chess at the park, bomb going off in the background"
        neg: ""
        seed: 42
        walk_seed: true
        guidance_scale: 4
        sample_steps: 20
        # num_frames: 1
        # fps: 1
meta:
  name: "lora_name"
  version: "1.0"
