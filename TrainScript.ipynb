{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8KQYvGDO7cg"
   },
   "outputs": [],
   "source": [
    "from transformers import   AutoProcessor, AutoModelForCausalLM\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from unittest.mock import patch\n",
    "from IPython.display import clear_output,display, HTML\n",
    "from itertools import islice\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "\n",
    "import io, base64, json, yaml, toml\n",
    "import numpy as np\n",
    "import requests, copy, os, torch, gc\n",
    "import torch.amp.autocast_mode\n",
    "import torchvision.transforms.functional as TVF\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name()\n",
    "print(gpu_name)\n",
    "if 'A100' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0'\n",
    "if 'L4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.9'\n",
    "if 'T4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '7.5'\n",
    "\n",
    "#API\n",
    "model_list = {\n",
    "    \"APIGemini | 2.0 Flash\" : \"gemini-2.0-flash-001\",\n",
    "    \"APIGemini | 2.0 Flash Lite\": \"gemini-2.0-flash-lite-preview-02-05\",\n",
    "    \"APIOpenAI | GPT 4-o mini\": \"gpt-4o-mini\",\n",
    "}\n",
    "\n",
    "def hug_down(link,path):\n",
    "  name = path.split('/')[-1]\n",
    "  folder = path.split(name)[0]\n",
    "  if \"blob\" in link:\n",
    "    link = link.replace(\"blob\",\"resolve\")\n",
    "  !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -s 16 -k 1M {link} -d {folder} -o {name}\n",
    "\n",
    "def encode_image(image):\n",
    "    with io.BytesIO() as image_buffer:\n",
    "        image.save(image_buffer, format=\"PNG\")\n",
    "        image_buffer.seek(0)\n",
    "        encoded_image = base64.b64encode(image_buffer.read()).decode('utf-8')\n",
    "    return encoded_image\n",
    "\n",
    "def api_check():\n",
    "    api_file = os.path.join(data_dir,\"Setting/API_key_for_sdvn_comfy_node.json\")\n",
    "    if os.path.exists(api_file):\n",
    "        with open(api_file, 'r', encoding='utf-8') as f:\n",
    "            api_list = json.load(f)\n",
    "        return api_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def api_caption(image, length:int, APIkey, Caption, prompt):\n",
    "    if APIkey == \"\":\n",
    "        api_list = api_check()\n",
    "        if api_check() != None:\n",
    "            if \"Gemini\" in Caption:\n",
    "                APIkey =  api_list[\"Gemini\"]\n",
    "            if \"OpenAI\" in Caption:\n",
    "                APIkey =  api_list[\"OpenAI\"]\n",
    "    model_name = model_list[Caption]\n",
    "    prompt += f\"Picture description, Send the description on demand, limit {length} words, only send me the answer, Always return English. \"\n",
    "    if 'Gemini' in Caption:\n",
    "        client = genai.Client(api_key=APIkey)\n",
    "        response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=[prompt, image])\n",
    "        answer = response.text\n",
    "    if \"OpenAI\" in Caption:\n",
    "        answer = \"\"\n",
    "        client = OpenAI(\n",
    "            api_key=APIkey)\n",
    "        if image != None:\n",
    "            image = encode_image(image)\n",
    "            prompt = [{\"type\": \"text\", \"text\": prompt, }, {\n",
    "                \"type\": \"image_url\", \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{image}\"}, },]\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                answer += chunk.choices[0].delta.content\n",
    "        if image != None:\n",
    "            answer = answer.split('return True')[-1]\n",
    "    return answer.strip()\n",
    "\n",
    "#Florence\n",
    "\n",
    "version = \"large\"\n",
    "device = torch.device(torch.cuda.current_device())\n",
    "\n",
    "def clean_directory(directory):\n",
    "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".safetensors\"]\n",
    "  for item in os.listdir(directory):\n",
    "      file_path = os.path.join(directory, item)\n",
    "      if os.path.isfile(file_path):\n",
    "          file_ext = os.path.splitext(item)[1]\n",
    "          if file_ext not in supported_types:\n",
    "              print(f\"Deleting file {item} from {directory}\")\n",
    "              os.remove(file_path)\n",
    "      elif os.path.isdir(file_path):\n",
    "          clean_directory(file_path)\n",
    "\n",
    "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "    \"\"\"Workaround for FlashAttention\"\"\"\n",
    "    if os.path.basename(filename) != \"modeling_florence2.py\":\n",
    "        return get_imports(filename)\n",
    "    imports = get_imports(filename)\n",
    "    # imports.remove(\"flash_attn\")\n",
    "    return imports\n",
    "\n",
    "def load_model(version, device):\n",
    "    model_dir = \"/content/Model\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    identifier = \"microsoft/Florence-2-\" + version\n",
    "\n",
    "    with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "        model = AutoModelForCausalLM.from_pretrained(identifier, cache_dir=model_dir, trust_remote_code=True)\n",
    "        processor = AutoProcessor.from_pretrained(identifier, cache_dir=model_dir, trust_remote_code=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    return (model, processor)\n",
    "\n",
    "def load(version, device):\n",
    "  if 'processor' not in globals():\n",
    "    global model, processor\n",
    "    model, processor = load_model(version, device)\n",
    "\n",
    "def run_example(task_prompt, image, max_new_tokens, num_beams, do_sample, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        early_stopping=False,\n",
    "        do_sample=do_sample,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "    return parsed_answer\n",
    "\n",
    "def florence_caption(task_prompt, image, max_new_tokens = 1024, num_beams = 3, do_sample = False, fill_mask = False, text_input=None):\n",
    "    if task_prompt == '<CAPTION>':\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "    elif task_prompt == '<DETAILED_CAPTION>':\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "    elif task_prompt == '<MORE_DETAILED_CAPTION>':\n",
    "        task_prompt = '<MORE_DETAILED_CAPTION>'\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "\n",
    "#Caption\n",
    "\n",
    "def caption_dir(image_dir,prompt):\n",
    "  if Caption == 'Florence':\n",
    "    load(version, device)\n",
    "  for img_file in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          caption_dir(file_path,prompt)\n",
    "      if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")):\n",
    "          img_path = os.path.join(image_dir, img_file)\n",
    "          image = Image.open(img_path).convert(\"RGB\")\n",
    "          if Caption == 'Florence':\n",
    "            cap = florence_caption(prompt,image).replace('The image shows','')\n",
    "          else:\n",
    "            cap = api_caption(image, Cap_prompt[Caption_Length][3], APIkey, Caption, API_Prompt)\n",
    "          txt_path = os.path.join(image_dir, f\"{os.path.splitext(img_file)[0]}{extension}\")\n",
    "          with open(txt_path, \"w\") as f:\n",
    "              f.write(cap)\n",
    "          print(f\"Miêu tả của ảnh {img_file}: {cap}\")\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def process_tags(filename, custom_tag, append, remove_tag):\n",
    "    contents = read_file(filename)\n",
    "    if remove_tag:\n",
    "      contents = contents.replace(custom_tag, \"\")\n",
    "    else:\n",
    "      tags = [tag.strip() for tag in contents.split(',')]\n",
    "      custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
    "      for custom_tag in custom_tags:\n",
    "          custom_tag = custom_tag.replace(\"_\", \" \")\n",
    "          if custom_tag not in tags:\n",
    "              if append:\n",
    "                  tags.append(custom_tag)\n",
    "              else:\n",
    "                  tags.insert(0, custom_tag)\n",
    "      contents = ', '.join(tags)\n",
    "    write_file(filename, contents)\n",
    "\n",
    "def check_dir(image_dir):\n",
    "  if not any([filename.endswith(extension) for filename in os.listdir(image_dir)]):\n",
    "      for filename in os.listdir(image_dir):\n",
    "          if filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\"))):\n",
    "              open(\n",
    "                  os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
    "                  \"w\",\n",
    "              ).close()\n",
    "\n",
    "def process_dir(image_dir, tag, append, remove_tag):\n",
    "  check_dir(image_dir)\n",
    "  for filename in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, filename)\n",
    "      if os.path.isdir(file_path) :\n",
    "          print(filename)\n",
    "          process_dir(file_path, tag, append, remove_tag)\n",
    "      elif filename.endswith(extension):\n",
    "          process_tags(file_path, tag, append, remove_tag)\n",
    "\n",
    "def add_forder_name(folder):\n",
    "  for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if os.path.isdir(file_path):\n",
    "      folder_name = os.path.basename(file_path)\n",
    "      try:\n",
    "          steps, name = folder_name.split('_', 1)\n",
    "          steps = int(steps)\n",
    "      except ValueError:\n",
    "          name = folder_name\n",
    "      name = name.replace(\"/\", \", \")\n",
    "      process_dir(file_path, name, False, False)\n",
    "      add_forder_name(file_path)\n",
    "\n",
    "def get_steps(folder):\n",
    "    folder_name = os.path.basename(folder)\n",
    "    try:\n",
    "        steps, name = folder_name.split('_', 1)\n",
    "        steps = int(steps)\n",
    "    except ValueError:\n",
    "        steps = Steps\n",
    "        name = folder_name\n",
    "    return steps, name\n",
    "\n",
    "def check_txt(image_dir):\n",
    "    txt_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.txt')]\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            txt_files += check_txt(file_path)\n",
    "    return txt_files\n",
    "\n",
    "def random_sample(folder):\n",
    "  import random\n",
    "  txt_files = check_txt(folder)\n",
    "  try:\n",
    "    sample = read_file(random.choice(txt_files))\n",
    "    sample = sample.replace('\"', r'\\\"')\n",
    "  except IndexError:\n",
    "    sample = \"girl portrait, smile\"\n",
    "  return sample\n",
    "\n",
    "def get_supported_images(folder):\n",
    "  import glob\n",
    "  supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")\n",
    "  list_img = [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
    "  for img_file in os.listdir(folder):\n",
    "      file_path = os.path.join(folder, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          list_img = list_img + get_supported_images(file_path)\n",
    "  return list_img\n",
    "\n",
    "def check_folder_train(folder):\n",
    "    if len(get_supported_images(folder)) > 0:\n",
    "      folder_dic = {\n",
    "        \"path\": folder,\n",
    "      }\n",
    "      print('=====================')\n",
    "      print(f'Thư mục train: {folder_dic[\"path\"]}')\n",
    "      print(f'  Số lượng ảnh: {len(get_supported_images(folder_dic[\"path\"]))}')\n",
    "      print('=====================')\n",
    "    else:\n",
    "      print(f\"Thư mục [ {folder} ] có thể không chứa ảnh được hỗ trợ, hãy kiểm tra lại (.png, .jpg, .jpeg, .webp, .bmp, .JPG, .JPEG, .PNG)\")\n",
    "\n",
    "def check_dir(image_dir):\n",
    "  if not any([filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\"))) for filename in os.listdir(image_dir)]):\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "\n",
    "def check_sub_dir(image_dir):\n",
    "    list_dir = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            list_dir += check_sub_dir(file_path)\n",
    "    if check_dir(image_dir):\n",
    "      list_dir += [image_dir]\n",
    "    return list_dir\n",
    "\n",
    "def repeat_dir(dir,num_repeats):\n",
    "    dir_name = dir.split('/')[-1]\n",
    "    try:\n",
    "        r = int(dir_name.split('_')[0])\n",
    "    except:\n",
    "        r = num_repeats\n",
    "    return r\n",
    "\n",
    "def dic2arg(config:dict):\n",
    "  arg = ''\n",
    "  for value in config:\n",
    "    arg += f'{value if str(config[value]) != \"False\" else \"\"} {\"\" if type(config[value]) == bool else config[value]} '\n",
    "  return arg\n",
    "\n",
    "def data_config(flip, color_aug, shuffle_caption):\n",
    "  data_config = {\n",
    "    \"general\": {\n",
    "        \"flip_aug\": flip,\n",
    "        \"color_aug\": color_aug,\n",
    "        \"keep_tokens_separator\": \"|||\",\n",
    "        \"shuffle_caption\": shuffle_caption,\n",
    "        \"caption_tag_dropout_rate\": 0,\n",
    "        \"caption_extension\": \".txt\"\n",
    "    },\n",
    "    \"datasets\": []\n",
    "  }\n",
    "  return data_config\n",
    "\n",
    "op = {\n",
    "    '--mixed_precision': 'bf16',\n",
    "    '--num_cpu_threads_per_process': 1,\n",
    "}\n",
    "\n",
    "def config(flux_path, clip_l_path, t5xxl_fp16_path, vae_path, dim, alpha, train_textencode, lr, lr_scheduler, epochs, save_every_n_epochs, dataset, output_dir, output_name):\n",
    "  config = {\n",
    "    '--pretrained_model_name_or_path': flux_path,\n",
    "    '--clip_l': clip_l_path,\n",
    "    '--t5xxl': t5xxl_fp16_path,\n",
    "    '--ae': vae_path,\n",
    "    '--cache_latents_to_disk': True,\n",
    "    '--save_model_as': 'safetensors',\n",
    "    '--sdpa': True,\n",
    "    '--persistent_data_loader_workers': True,\n",
    "    '--max_data_loader_n_workers': 2,\n",
    "    '--seed': 42,\n",
    "    '--gradient_checkpointing': True,\n",
    "    '--mixed_precision': 'bf16',\n",
    "    '--save_precision': 'bf16',\n",
    "    '--network_module' :'networks.lora_flux',\n",
    "    '--network_dim': dim,\n",
    "    '--network_alpha': alpha,\n",
    "    '--network_train_unet_only': False if train_textencode else True,\n",
    "    '--network_args': \"train_t5xxl=True\" if train_textencode else False,\n",
    "    '--optimizer_type': 'adamw8bit',\n",
    "    '--learning_rate': lr,\n",
    "    '--lr_scheduler': lr_scheduler, #constant, cosine, cosine_with_restarts, linear, adafactor, constant_with_warmup, polynomial\n",
    "    '--unet_lr': False, #1e-4\n",
    "    '--text_encoder_lr': False, #1e-4\n",
    "    '--cache_text_encoder_outputs': False,\n",
    "    '--cache_text_encoder_outputs_to_disk': False,\n",
    "    '--fp8_base': True,\n",
    "    '--highvram': True,\n",
    "    '--max_train_epochs': epochs,\n",
    "    '--save_every_n_epochs': save_every_n_epochs,\n",
    "    '--save_every_n_steps': False,\n",
    "    '--dataset_config': dataset,\n",
    "    '--output_dir': output_dir,\n",
    "    '--output_name': output_name,\n",
    "    '--timestep_sampling': 'shift',\n",
    "    '--discrete_flow_shift': 3.1582,\n",
    "    '--model_prediction_type': 'raw',\n",
    "    '--guidance_scale': 1.0\n",
    "  }\n",
    "  return config\n",
    "\n",
    "def extra(output_name, author, description, comment, save_state, resume, wandb, sample_steps):\n",
    "  extra = {\n",
    "      '--metadata_title': output_name,\n",
    "      '--metadata_author': f'\"{author}\"',\n",
    "      '--metadata_description': f'\"{description}\"',\n",
    "      '--metadata_license': False, # \"MIT\"\n",
    "      '--metadata_tags': False, # \"sdvn.me\"\n",
    "      '--no_metadata': False,\n",
    "      '--training_comment': f'\"{comment}\"',\n",
    "      '--save_n_epoch_ratio': False,\n",
    "      '--save_last_n_epochs': False,\n",
    "      '--save_last_n_epochs_state': False,\n",
    "      '--save_last_n_steps': False,\n",
    "      '--save_last_n_steps_state': False,\n",
    "      '--save_state': save_state,\n",
    "      '--save_state_on_train_end': True,\n",
    "      '--resume': resume if resume != '' else False, #Path\n",
    "      '--log_with': 'wandb' if wandb else False, # tensorboard,wandb,all\n",
    "      '--wandb_run_name': f'fluxlora_{output_name}',\n",
    "      '--wandb_api_key': 'b037424918f8e39bdbea8dd24561aed45985ece9',\n",
    "      '--sample_every_n_steps': False if sample_steps <= 0 else sample_steps,\n",
    "      '--sample_at_first': True,\n",
    "      '--sample_every_n_epochs': False,\n",
    "      '--sample_prompts': '/content/prompt.txt',\n",
    "      '--sample_sampler': 'euler',\n",
    "  }\n",
    "  return extra\n",
    "\n",
    "def prompt(sample_prompt, sample_size, TrainFolder):\n",
    "  prompt = f'{sample_prompt} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}'\n",
    "  prompt = f\"\"\"\n",
    "  #prompt 1\n",
    "  {prompt}\n",
    "  #prompt 2\n",
    "  {random_sample(TrainFolder)} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}\n",
    "  #prompt 3\n",
    "  {random_sample(TrainFolder)} --w {sample_size.split(\",\")[0]} --h {sample_size.split(\",\")[1]}\n",
    "  \"\"\"\n",
    "  write_file('/content/prompt.txt',prompt)\n",
    "\n",
    "def dataset_file(resolution, batch_size, image_dir, num_repeats, data_config, dataset):\n",
    "  resolutions = resolution.split(',')\n",
    "  index = 0\n",
    "  for resolution in resolutions:\n",
    "    data_config[\"datasets\"].append({\n",
    "              \"batch_size\": batch_size,\n",
    "              \"enable_bucket\": True,\n",
    "              \"resolution\": [int(resolution), int(resolution)],\n",
    "              \"subsets\": []\n",
    "              })\n",
    "    for dir in check_sub_dir(image_dir):\n",
    "      data_config[\"datasets\"][index][\"subsets\"] += [{\n",
    "          \"image_dir\": dir,\n",
    "          \"num_repeats\": repeat_dir(dir,num_repeats)\n",
    "      }]\n",
    "    index += 1\n",
    "\n",
    "  with open(dataset, \"w\") as file:\n",
    "      toml.dump(data_config, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
