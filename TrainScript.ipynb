{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8KQYvGDO7cg"
   },
   "outputs": [],
   "source": [
    "# @title Script\n",
    "\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from unittest.mock import patch\n",
    "from IPython.display import clear_output,display, HTML\n",
    "from itertools import islice\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "\n",
    "import io, base64, json, yaml, toml\n",
    "import numpy as np\n",
    "import requests, copy, os, torch, gc, re\n",
    "import torch.amp.autocast_mode\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name()\n",
    "print(gpu_name)\n",
    "if 'A100' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0'\n",
    "if 'L4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.9'\n",
    "if 'T4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '7.5'\n",
    "\n",
    "#API\n",
    "model_list = {\n",
    "    \"APIGemini | 2.5 Pro\": \"gemini-2.5-pro\",\n",
    "    \"APIGemini | 2.5 Flash\": \"gemini-2.5-flash\",\n",
    "    \"APIGemini | 2.0 Flash\" : \"gemini-2.0-flash\",\n",
    "    \"APIGemini | 2.0 Flash Lite\": \"gemini-2.0-flash-lite\",\n",
    "    \"APIOpenAI | GPT 4-o mini\": \"gpt-4o-mini\",\n",
    "    \"APIOpenAI | GPT o4-mini\": \"o4-mini\",\n",
    "}\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/StableDiffusionVN/SDVN-WebUI/refs/heads/main/model_lib.json\"\n",
    "response = requests.get(url)\n",
    "model_train_list = json.loads(response.text)\n",
    "\n",
    "lora_train_py = {\n",
    "    \"Flux\": \"flux_train_network.py\",\n",
    "    \"SDXL\": \"sdxl_train_network.py\",\n",
    "    \"SD15\": \"train_network.py\"\n",
    "}\n",
    "db_train_py = {\n",
    "    \"Flux\": \"flux_train.py\",\n",
    "    \"SDXL\": \"sdxl_train.py\",\n",
    "    \"SD15\": \"train_db.py\"\n",
    "}\n",
    "def encode_image(image):\n",
    "    with io.BytesIO() as image_buffer:\n",
    "        image.save(image_buffer, format=\"PNG\")\n",
    "        image_buffer.seek(0)\n",
    "        encoded_image = base64.b64encode(image_buffer.read()).decode('utf-8')\n",
    "    return encoded_image\n",
    "\n",
    "def api_check():\n",
    "    api_file = os.path.join(data_dir,\"Setting/API_key_for_sdvn_comfy_node.json\")\n",
    "    if os.path.exists(api_file):\n",
    "        with open(api_file, 'r', encoding='utf-8') as f:\n",
    "            api_list = json.load(f)\n",
    "        return api_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def api_caption(image, length:int, APIkey, Caption, prompt):\n",
    "    if APIkey == \"\":\n",
    "        api_list = api_check()\n",
    "        if api_check() != None:\n",
    "            if \"Gemini\" in Caption:\n",
    "                APIkey =  api_list[\"Gemini\"]\n",
    "            if \"OpenAI\" in Caption:\n",
    "                APIkey =  api_list[\"OpenAI\"]\n",
    "    model_name = model_list[Caption]\n",
    "    prompt += f\"Picture description, Send the description on demand, limit {length} words, only send me the answer, Always return English. \"\n",
    "    if 'Gemini' in Caption:\n",
    "        client = genai.Client(api_key=APIkey)\n",
    "        response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=[prompt, image])\n",
    "        answer = response.text\n",
    "    if \"OpenAI\" in Caption:\n",
    "        answer = \"\"\n",
    "        client = OpenAI(\n",
    "            api_key=APIkey)\n",
    "        if image != None:\n",
    "            image = encode_image(image)\n",
    "            prompt = [{\"type\": \"text\", \"text\": prompt, }, {\n",
    "                \"type\": \"image_url\", \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{image}\"}, },]\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                answer += chunk.choices[0].delta.content\n",
    "        if image != None:\n",
    "            answer = answer.split('return True')[-1]\n",
    "    return answer.strip()\n",
    "\n",
    "#Florence\n",
    "\n",
    "version = \"large\"\n",
    "device = torch.device(torch.cuda.current_device())\n",
    "\n",
    "def clean_directory(directory):\n",
    "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".safetensors\"]\n",
    "  for item in os.listdir(directory):\n",
    "      file_path = os.path.join(directory, item)\n",
    "      if os.path.isfile(file_path):\n",
    "          file_ext = os.path.splitext(item)[1]\n",
    "          if file_ext not in supported_types:\n",
    "              print(f\"Deleting file {item} from {directory}\")\n",
    "              os.remove(file_path)\n",
    "      elif os.path.isdir(file_path):\n",
    "          clean_directory(file_path)\n",
    "\n",
    "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "    \"\"\"Workaround for FlashAttention\"\"\"\n",
    "    if os.path.basename(filename) != \"modeling_florence2.py\":\n",
    "        return get_imports(filename)\n",
    "    imports = get_imports(filename)\n",
    "    # imports.remove(\"flash_attn\")\n",
    "    return imports\n",
    "\n",
    "def load_model(version, device):\n",
    "    from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "    model_dir = \"/content/Model\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    identifier = \"microsoft/Florence-2-\" + version\n",
    "\n",
    "    with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "        model = AutoModelForCausalLM.from_pretrained(identifier, cache_dir=model_dir, trust_remote_code=True)\n",
    "        processor = AutoProcessor.from_pretrained(identifier, cache_dir=model_dir, trust_remote_code=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    return (model, processor)\n",
    "\n",
    "def load(version, device):\n",
    "  if 'processor' not in globals():\n",
    "    global model, processor\n",
    "    model, processor = load_model(version, device)\n",
    "\n",
    "def run_example(task_prompt, image, max_new_tokens, num_beams, do_sample, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        early_stopping=False,\n",
    "        do_sample=do_sample,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "    return parsed_answer\n",
    "\n",
    "def florence_caption(task_prompt, image, max_new_tokens = 1024, num_beams = 3, do_sample = False, fill_mask = False, text_input=None):\n",
    "    if task_prompt == '<CAPTION>':\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "    elif task_prompt == '<DETAILED_CAPTION>':\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "    elif task_prompt == '<MORE_DETAILED_CAPTION>':\n",
    "        task_prompt = '<MORE_DETAILED_CAPTION>'\n",
    "        result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "        return result[task_prompt].replace(\"\\n\", \"\")\n",
    "\n",
    "#Caption\n",
    "\n",
    "def caption_dir(image_dir,prompt):\n",
    "  if Caption == 'Florence':\n",
    "    load(version, device)\n",
    "  if Caption == 'WD14':\n",
    "    print(f'Tạo caption WD14: {image_dir}')\n",
    "    run = f\"python /content/sd-scripts/finetune/tag_images_by_wd14_tagger.py --onnx --repo_id SmilingWolf/wd-eva02-large-tagger-v3 --thresh {prompt[1]} --batch_size 4 '{image_dir}'\"\n",
    "    !{run}\n",
    "  for img_file in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          caption_dir(file_path,prompt)\n",
    "      if Caption != 'WD14':\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if Caption == 'Florence':\n",
    "              cap = florence_caption(prompt[0],image).replace('The image shows','')\n",
    "            else:\n",
    "              cap = api_caption(image, prompt[2], APIkey, Caption, API_Prompt)\n",
    "            txt_path = os.path.join(image_dir, f\"{os.path.splitext(img_file)[0]}{extension}\")\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                f.write(cap)\n",
    "            print(f\"Miêu tả của ảnh {img_file}: {cap}\")\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def process_tags(filename, custom_tag, append, remove_tag):\n",
    "    contents = read_file(filename)\n",
    "    if remove_tag:\n",
    "      contents = contents.replace(custom_tag, \"\")\n",
    "    else:\n",
    "      tags = [tag.strip() for tag in contents.split(',')]\n",
    "      custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
    "      for custom_tag in custom_tags:\n",
    "          custom_tag = custom_tag.replace(\"_\", \" \")\n",
    "          if custom_tag not in tags:\n",
    "              if append:\n",
    "                  tags.append(custom_tag)\n",
    "              else:\n",
    "                  tags.insert(0, custom_tag)\n",
    "      contents = ', '.join(tags)\n",
    "    write_file(filename, contents)\n",
    "\n",
    "def check_dir(image_dir):\n",
    "  if not any([filename.endswith(extension) for filename in os.listdir(image_dir)]):\n",
    "      for filename in os.listdir(image_dir):\n",
    "          if filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\"))):\n",
    "              open(\n",
    "                  os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
    "                  \"w\",\n",
    "              ).close()\n",
    "\n",
    "def process_dir(image_dir, tag, append, remove_tag):\n",
    "  check_dir(image_dir)\n",
    "  for filename in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, filename)\n",
    "      if os.path.isdir(file_path) :\n",
    "          print(filename)\n",
    "          process_dir(file_path, tag, append, remove_tag)\n",
    "      elif filename.endswith(extension):\n",
    "          process_tags(file_path, tag, append, remove_tag)\n",
    "\n",
    "def add_forder_name(folder):\n",
    "  for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if os.path.isdir(file_path):\n",
    "      folder_name = os.path.basename(file_path)\n",
    "      try:\n",
    "          steps, name = folder_name.split('_', 1)\n",
    "          steps = int(steps)\n",
    "      except ValueError:\n",
    "          name = folder_name\n",
    "      name = name.replace(\"/\", \", \")\n",
    "      process_dir(file_path, name, False, False)\n",
    "      add_forder_name(file_path)\n",
    "\n",
    "def get_steps(folder):\n",
    "    folder_name = os.path.basename(folder)\n",
    "    try:\n",
    "        steps, name = folder_name.split('_', 1)\n",
    "        steps = int(steps)\n",
    "    except ValueError:\n",
    "        steps = Steps\n",
    "        name = folder_name\n",
    "    return steps, name\n",
    "\n",
    "def check_txt(image_dir):\n",
    "    txt_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.txt')]\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            txt_files += check_txt(file_path)\n",
    "    return txt_files\n",
    "\n",
    "def random_sample(folder):\n",
    "  import random\n",
    "  txt_files = check_txt(folder)\n",
    "  try:\n",
    "    sample = read_file(random.choice(txt_files))\n",
    "    sample = sample.replace('\"', r'\\\"')\n",
    "  except IndexError:\n",
    "    sample = \"girl portrait, smile\"\n",
    "  return sample\n",
    "\n",
    "def get_supported_images(folder):\n",
    "  import glob\n",
    "  supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")\n",
    "  list_img = [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
    "  for img_file in os.listdir(folder):\n",
    "      file_path = os.path.join(folder, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          list_img = list_img + get_supported_images(file_path)\n",
    "  return list_img\n",
    "\n",
    "def check_folder_train(folder):\n",
    "    if len(get_supported_images(folder)) > 0:\n",
    "      folder_dic = {\n",
    "        \"path\": folder,\n",
    "      }\n",
    "      print('=====================')\n",
    "      print(f'Thư mục train: {folder_dic[\"path\"]}')\n",
    "      print(f'  Số lượng ảnh: {len(get_supported_images(folder_dic[\"path\"]))}')\n",
    "      print('=====================')\n",
    "    else:\n",
    "      print(f\"Thư mục [ {folder} ] có thể không chứa ảnh được hỗ trợ, hãy kiểm tra lại (.png, .jpg, .jpeg, .webp, .bmp, .JPG, .JPEG, .PNG)\")\n",
    "\n",
    "def check_dir_image(image_dir):\n",
    "  if not any([filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\"))) for filename in os.listdir(image_dir)]):\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "\n",
    "def check_sub_dir(image_dir):\n",
    "    list_dir = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            list_dir += check_sub_dir(file_path)\n",
    "    if check_dir_image(image_dir):\n",
    "      list_dir += [image_dir]\n",
    "    return list_dir\n",
    "\n",
    "def repeat_dir(dir,num_repeats):\n",
    "    dir_name = dir.split('/')[-1]\n",
    "    try:\n",
    "        r = int(dir_name.split('_')[0])\n",
    "    except:\n",
    "        r = num_repeats\n",
    "    return r\n",
    "\n",
    "def dic2arg(config:dict):\n",
    "  arg = ''\n",
    "  for value in config:\n",
    "    arg += f'{value if str(config[value]) != \"False\" else \"\"} {\"\" if type(config[value]) == bool else config[value]} '\n",
    "  return arg\n",
    "\n",
    "def civit_downlink(link):\n",
    "  !wget {link} -q -O model.html\n",
    "  try:\n",
    "      # Mở tệp và đọc nội dung\n",
    "      with open('model.html', 'r', encoding='utf-8') as file:\n",
    "          html_content = file.read()\n",
    "      pattern = r'\"modelVersionId\":(\\d+),'\n",
    "      model_id = re.findall(pattern, html_content)\n",
    "      if model_id:\n",
    "        api_link = f'https://civitai.com/api/download/models/{model_id[0]}'\n",
    "        print(f'Download model id_link: {api_link}')\n",
    "        return api_link\n",
    "      else:\n",
    "          return \"Không tìm thấy đoạn nội dung phù hợp.\"\n",
    "  except requests.RequestException as e:\n",
    "      return f\"Lỗi khi tải trang: {e}\"\n",
    "\n",
    "def check_link(link):\n",
    "  if 'huggingface.co' in link:\n",
    "    if 'blob' in link:\n",
    "      link = link.replace('blob', 'resolve')\n",
    "  if 'civitai.com' in link:\n",
    "    if 'civitai.com/models' in link:\n",
    "      link = civit_downlink(link)\n",
    "    link = link+'?token=8c7337ac0c39fe4133ae19a3d65b806f'\n",
    "  return link\n",
    "\n",
    "def aria_down(link,path,name, over = False):\n",
    "  print(link)\n",
    "  link = check_link(link)\n",
    "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {'--allow-overwrite=true' if over else ''} {link} -d  {path} -o {name}\n",
    "\n",
    "def download_lib(model):\n",
    "  if 'https:' in model:\n",
    "    model = model.replace('&', '\\&')\n",
    "    aria_down(model,model_folder,\"model.safetensors\", True)\n",
    "    model_path = f\"{model_folder}/model.safetensors\"\n",
    "  elif '/content/' in model:\n",
    "    model_path = model\n",
    "  else:\n",
    "    if not any(ext in model for ext in ['.ckpt', '.gguf', '.safetensors']):\n",
    "        model += '.safetensors'\n",
    "    if model not in  model_train_list:\n",
    "      model = \"RealisticVision51.safetensors\" if TrainType == 'SD15' else \"SDXL-Base.safetensors\"\n",
    "    aria_down(model_train_list[model],model_folder,model)\n",
    "    model_path = f\"{model_folder}/{model}\"\n",
    "  return model_path\n",
    "\n",
    "def hug_down(link,path):\n",
    "  name = path.split('/')[-1]\n",
    "  folder = path.split(name)[0]\n",
    "  if \"blob\" in link:\n",
    "    link = link.replace(\"blob\",\"resolve\")\n",
    "  !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -s 16 -k 1M {link} -d {folder} -o {name}\n",
    "\n",
    "#Model download\n",
    "\n",
    "flux = \"https://huggingface.co/StableDiffusionVN/Flux/blob/main/Unet/flux1-dev.safetensors\"\n",
    "clip_l = \"https://huggingface.co/StableDiffusionVN/Flux/blob/main/Clip/clip_l.safetensors\"\n",
    "t5xxl_fp16 = \"https://huggingface.co/StableDiffusionVN/Flux/blob/main/Clip/t5xxl_fp16.safetensors\"\n",
    "vae = \"https://huggingface.co/StableDiffusionVN/Flux/blob/main/Vae/flux_vae.safetensors\"\n",
    "\n",
    "flux_path = f\"{model_folder}/flux1-dev.safetensors\"\n",
    "clip_l_path = f\"{model_folder}/clip_l.safetensors\"\n",
    "t5xxl_fp16_path = f\"{model_folder}/t5xxl_fp16.safetensors\"\n",
    "vae_path = f\"{model_folder}/flux_vae.safetensors\"\n",
    "\n",
    "if TrainType == \"Flux\":\n",
    "  hug_down(flux,flux_path)\n",
    "  hug_down(clip_l,clip_l_path)\n",
    "  hug_down(t5xxl_fp16,t5xxl_fp16_path)\n",
    "  hug_down(vae,vae_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
